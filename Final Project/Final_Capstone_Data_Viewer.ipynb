{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steering Model Visualization\n",
    "This code is a slightly modified version of the code produced by the comma.ai team. Original located here:\n",
    "https://github.com/commaai/research/blob/master/view_steering_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Notes:\n",
    "\n",
    "# len(test_images) <> len(df_truth) because model required predictions in batches of 128. Largest number divisible by \n",
    "# 128 is 5504\n",
    "\n",
    "#!/usr/bin/env python\n",
    "import pandas as pd\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pygame\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from skimage import io\n",
    "import math\n",
    "\n",
    "#Model \"lookback\" was 3 for LSTM layers\n",
    "lookback = 3\n",
    "\n",
    "pygame.init()\n",
    "size = (320*2, 160*3)\n",
    "pygame.display.set_caption(\"comma.ai data viewer\")\n",
    "screen = pygame.display.set_mode(size, pygame.DOUBLEBUF)\n",
    "\n",
    "camera_surface = pygame.surface.Surface((320,240),0,24).convert()\n",
    "\n",
    "#model = load_model(r'C:\\Users\\ryan\\Desktop\\Thinkful DS Sample Data - Main Course\\Final Capstone\\Final Model, Notebook, Test & Val Arrays\\Final Model and Test Set\\m51e.h5')\n",
    "\n",
    "df_test = pd.DataFrame(np.load(r'C:\\Users\\ryan\\Desktop\\Thinkful DS Sample Data - Main Course\\Final Capstone\\Final Model, Notebook, Test & Val Arrays\\Final Model and Test Set\\test_preds.npy'))\n",
    "df_test.columns = [['steering_angle']]\n",
    "df_truth = pd.DataFrame(np.load(r'C:\\Users\\ryan\\Desktop\\Thinkful DS Sample Data - Main Course\\Final Capstone\\Final Model, Notebook, Test & Val Arrays\\Final Model and Test Set\\y_test.npy'))\n",
    "df_truth.columns = [['steering_angle']]\n",
    "\n",
    "\n",
    "c_steer_test = pd.read_csv(r'C:\\Users\\ryan\\Desktop\\Thinkful DS Sample Data - Main Course\\Final Capstone\\CH2_final_evaluation.csv')\n",
    "test_root = os.path.normpath(r'C:\\Users\\ryan\\Desktop\\Thinkful DS Sample Data - Main Course\\Final Capstone\\center')\n",
    "\n",
    "\n",
    "# ***** get perspective transform for images *****\n",
    "from skimage import transform as tf\n",
    "\n",
    "rsrc = \\\n",
    " [[43.45456230828867, 118.00743250075844],\n",
    "  [104.5055617352614, 69.46865203761757],\n",
    "  [114.86050156739812, 60.83953551083698],\n",
    "  [129.74572757609468, 50.48459567870026],\n",
    "  [132.98164627363735, 46.38576532847949],\n",
    "  [301.0336906326895, 98.16046448916306],\n",
    "  [238.25686790036065, 62.56535881619311],\n",
    "  [227.2547443287154, 56.30924933427718],\n",
    "  [209.13359962247614, 46.817221154818526],\n",
    "  [203.9561297064078, 43.5813024572758]]\n",
    "rdst = \\\n",
    " [[10.822125594094452, 1.42189132706374],\n",
    "  [21.177065426231174, 1.5297552836484982],\n",
    "  [25.275895776451954, 1.42189132706374],\n",
    "  [36.062291434927694, 1.6376192402332563],\n",
    "  [40.376849698318004, 1.42189132706374],\n",
    "  [11.900765159942026, -2.1376192402332563],\n",
    "  [22.25570499207874, -2.1376192402332563],\n",
    "  [26.785991168638553, -2.029755283648498],\n",
    "  [37.033067044190524, -2.029755283648498],\n",
    "  [41.67121717733509, -2.029755283648498]]\n",
    "\n",
    "tform3_img = tf.ProjectiveTransform()\n",
    "tform3_img.estimate(np.array(rdst), np.array(rsrc))\n",
    "\n",
    "def perspective_tform(x, y):\n",
    "    p1, p2 = tform3_img((x,y))[0]\n",
    "    return p2, p1\n",
    "\n",
    "# ***** functions to draw lines *****\n",
    "def draw_pt(img, x, y, color, sz=3):\n",
    "    row, col = perspective_tform(x, y)\n",
    "    #print('row', row)\n",
    "    #print('col', col)\n",
    "    #print(img.shape)\n",
    "    #Had to reshape based on input image shape (RM)\n",
    "    tmp = img.swapaxes(0,2).swapaxes(1,2)\n",
    "    if row >= 0 and row < tmp.shape[0] and\\\n",
    "    col >= 0 and col < tmp.shape[1]:\n",
    "        #Had to ensure integer values for rows and columns or it wouldn't work (RM)\n",
    "        #Also added 75 and 160 pixels to row and column dimensions to properly center actual/prediction display lines\n",
    "        tmp[math.floor(row+75)-sz:math.floor(row+75)+sz, math.floor(col+160)-sz:math.floor(col+160)+sz] = color\n",
    "\n",
    "def draw_path(img, path_x, path_y, color):\n",
    "    for x, y in zip(path_x, path_y):\n",
    "        draw_pt(img, x, y, color)\n",
    "\n",
    "# ***** functions to draw predicted path *****\n",
    "\n",
    "def calc_curvature(v_ego, angle_steers, angle_offset=0):\n",
    "    deg_to_rad = np.pi/180.\n",
    "    slip_fator = 0.0014 # slip factor obtained from real data\n",
    "    steer_ratio = 15.3  # from http://www.edmunds.com/acura/ilx/2016/road-test-specs/\n",
    "    wheel_base = 2.67   # from http://www.edmunds.com/acura/ilx/2016/sedan/features-specs/\n",
    "\n",
    "    angle_steers_rad = (angle_steers - angle_offset) #* deg_to_rad\n",
    "    curvature = angle_steers_rad/(steer_ratio * wheel_base * (1. + slip_fator * v_ego**2))\n",
    "    #Had to multiply by -1 to get direction correct (RM)\n",
    "    return -1*curvature\n",
    "\n",
    "def calc_lookahead_offset(v_ego, angle_steers, d_lookahead, angle_offset=0):\n",
    "    #*** this function returns the lateral offset given the steering angle, speed and the lookahead distance\n",
    "    curvature = calc_curvature(v_ego, angle_steers, angle_offset)\n",
    "\n",
    "  # clip is to avoid arcsin NaNs due to too sharp turns\n",
    "    y_actual = d_lookahead * np.tan(np.arcsin(np.clip(d_lookahead * curvature, -0.999, 0.999))/2.)\n",
    "    return y_actual, curvature\n",
    "\n",
    "def draw_path_on(img, speed_ms, angle_steers, color=(0,0,255)):\n",
    "    path_x = np.arange(0., 50.1, 0.5)\n",
    "    path_y, _ = calc_lookahead_offset(speed_ms, angle_steers, path_x)\n",
    "    draw_path(img, path_x, path_y, color)\n",
    "\n",
    "# ***** main loop *****\n",
    "if __name__ == \"__main__\":\n",
    "  #parser = argparse.ArgumentParser(description='Path viewer')\n",
    "  #parser.add_argument('model', type=str, help='Path to model definition json. Model weights should be on the same path.')\n",
    "  #parser.add_argument('--dataset', type=str, default=\"2016-06-08--11-46-01\", help='Dataset/video clip name')\n",
    "  #args = parser.parse_args()\n",
    "\n",
    "\n",
    "\n",
    "  # default dataset is the validation data on the highway\n",
    "  #dataset = args.dataset\n",
    "  #skip = 300\n",
    "\n",
    "  #log = h5py.File(\"dataset/log/\"+dataset+\".h5\", \"r\")\n",
    "  #cam = h5py.File(\"dataset/camera/\"+dataset+\".h5\", \"r\")\n",
    "\n",
    "  #print(log.keys())\n",
    "    #Hard-coded speed rather than reading from some log file (RM)\n",
    "    #speed_ms = 2 #log['speed'][i]  \n",
    "\n",
    "#Iterate over test images\n",
    "    for i in range(len(df_test)):\n",
    "    #for i in range(1):\n",
    "    #if i%100 == 0:\n",
    "    #  print(\"%.2f seconds elapsed\" % (i/100.0))\n",
    "    #img = cam['X'][log['cam1_ptr'][i]].swapaxes(0,2).swapaxes(0,1)\n",
    "        img = skimage.io.imread(test_root + '\\\\' + str(c_steer_test['frame_id'][i+lookback]) + '.jpg').swapaxes(0,2).swapaxes(0,1)\n",
    "    #print('img', img.shape)\n",
    "    #img = skimage.transform.resize(img, (img.shape[0] / (3/2), img.shape[1])).swapaxes(0,2).swapaxes(0,1)\n",
    "    \n",
    "        predicted_steers = df_test['steering_angle'].loc[i]\n",
    "        angle_steers = df_truth['steering_angle'].loc[i]\n",
    "    \n",
    "        #Hard-coded speed rather than reading from some log file (RM)\n",
    "        speed_ms = 0.2 #log['speed'][i]\n",
    "\n",
    "        #Had to change division on angle steers from 10 to 3 to have it make visual sense on display (RM)\n",
    "        draw_path_on(img, speed_ms, -angle_steers/3.0)\n",
    "        draw_path_on(img, speed_ms, -predicted_steers/3.0, (0, 255, 0))\n",
    "\n",
    "    # draw on\n",
    "    #print('img', img.shape)\n",
    "    #print('cam', camera_surface.shape)\n",
    "        camera_surface_2x = pygame.transform.scale2x(camera_surface)\n",
    "        pygame.surfarray.blit_array(camera_surface_2x, img.swapaxes(1,2))\n",
    "    #camera_surface_2x = pygame.transform.scale2x(camera_surface)\n",
    "        screen.blit(camera_surface_2x, (0,0))\n",
    "        \n",
    "        #Save images (only need to run this once to make an image set which we can then transform into a video)\n",
    "        #pygame.image.save(camera_surface_2x, r'C:\\Users\\ryan\\Desktop\\Thinkful DS Sample Data - Main Course\\Final Capstone\\Final Model, Notebook, Test & Val Arrays\\Img_Output\\output_steer_image{}.png'.format(i))\n",
    "        \n",
    "        pygame.display.flip()\n",
    "    # Do nothing in pygame window in response to mouse click (RM)\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.MOUSEBUTTONUP:\n",
    "                None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now create a video file of all of those images\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "image_folder = r'C:\\Users\\ryan\\Desktop\\Thinkful DS Sample Data - Main Course\\Final Capstone\\Final Model, Notebook, Test & Val Arrays\\Img_Output'\n",
    "video_name =  r'C:\\Users\\ryan\\Desktop\\Thinkful DS Sample Data - Main Course\\Final Capstone\\Final Model, Notebook, Test & Val Arrays\\Img_Output\\output_video.mp4'\n",
    "\n",
    "images = []\n",
    "for i in range(len(df_test)):\n",
    "    images.append('output_steer_image{}.png'.format(i))\n",
    "\n",
    "# Determine the width and height from the first image\n",
    "image_path = os.path.join(image_folder, images[0])\n",
    "frame = cv2.imread(image_path)\n",
    "cv2.imshow('video',frame)\n",
    "height, width, channels = frame.shape\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "video = cv2.VideoWriter(video_name, fourcc, 20.0, (width,height))\n",
    "\n",
    "for image in images:\n",
    "\n",
    "    image_path = os.path.join(image_folder, image)\n",
    "    frame = cv2.imread(image_path)\n",
    "\n",
    "    video.write(frame) # Write out frame to video\n",
    "\n",
    "    cv2.imshow('video',frame)\n",
    "\n",
    "# Release everything if job is finished\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check out the video!\n",
    "\n",
    "https://youtu.be/c6e7YWUdXpI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
